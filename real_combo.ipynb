{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "# import requests\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "# import wandb\n",
    "# from PIL import Image\n",
    "# from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import wandb\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables for API keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API key not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dalle_download():\n",
    "    \"\"\"Test DALL-E image generation and download\"\"\"\n",
    "    try:\n",
    "        # Test prompt\n",
    "        test_prompt = \"A simple test image of a blue circle\"\n",
    "        \n",
    "        print(\"Testing DALL-E image generation...\")\n",
    "        image_url = generate_dalle_image(test_prompt, OPENAI_API_KEY)\n",
    "        \n",
    "        # Create test directory if it doesn't exist\n",
    "        os.makedirs('test', exist_ok=True)\n",
    "        \n",
    "        # Download the image\n",
    "        print(\"Downloading test image...\")\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            # Save the image\n",
    "            test_path = os.path.join('test', 'dalle_test.png')\n",
    "            with open(test_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Test successful! Image saved to {test_path}\")\n",
    "            \n",
    "            # Try loading the image with PIL to verify it's valid\n",
    "            try:\n",
    "                Image.open(test_path)\n",
    "                print(\"Image format verified successfully!\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"Error verifying image format: {e}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Test failed with error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb with your API key\n",
    "wandb.login(key=\"7e7d55f5967d9b48d5c46f5008eaa5ad71e02d89\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# def generate_dalle_image(prompt, api_key):\n",
    "#     \"\"\"\n",
    "#     Generate an image using DALL-E based on the given prompt\n",
    "    \n",
    "#     Args:\n",
    "#         prompt (str): The text prompt to generate the image from\n",
    "#         api_key (str): OpenAI API key\n",
    "        \n",
    "#     Returns:\n",
    "#         str: URL of the generated image\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         client = OpenAI(api_key=api_key)\n",
    "        \n",
    "#         response = client.images.generate(\n",
    "#             model=\"dall-e-3\",\n",
    "#             prompt=prompt,\n",
    "#             size=\"1024x1024\",\n",
    "#             quality=\"standard\",\n",
    "#             n=1,\n",
    "#         )\n",
    "        \n",
    "#         return response.data[0].url\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error generating DALL-E image: {str(e)}\")\n",
    "#         raise\n",
    "\n",
    "\n",
    "\n",
    "# #USED FOR DALL-E-3 IMAGE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=50, period=3600)  # Limiting to 50 calls per hour\n",
    "def generate_dalle_image(prompt, api_key):\n",
    "    \"\"\"\n",
    "    Generate an image using DALL-E based on the given prompt, with rate limiting\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to generate the image from\n",
    "        api_key (str): OpenAI API key\n",
    "        \n",
    "    Returns:\n",
    "        str: URL of the generated image, or None if generation fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        \n",
    "        response = client.images.generate(\n",
    "            model=\"dall-e-2\",  # Changed to DALL-E 2 for lower cost\n",
    "            prompt=prompt,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "        )\n",
    "        \n",
    "        return response.data[0].url\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating DALL-E image: {str(e)}\")\n",
    "        return None  # Return None instead of raising an exception for graceful failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_dalle_generation(num_images=5):\n",
    "    \"\"\"\n",
    "    Development-friendly function that creates and returns paths to test images\n",
    "    instead of generating new ones through the API\n",
    "    \n",
    "    Args:\n",
    "        num_images (int): Number of test images to create/use\n",
    "        \n",
    "    Returns:\n",
    "        list: Paths to test images\n",
    "    \"\"\"\n",
    "    test_images = []\n",
    "    os.makedirs('test_images', exist_ok=True)\n",
    "    \n",
    "    # Create or use sample images for testing\n",
    "    for i in range(num_images):\n",
    "        test_path = f'test_images/test_image_{i}.jpg'\n",
    "        if not os.path.exists(test_path):\n",
    "            # Create a simple test image using PIL\n",
    "            img = Image.new('RGB', (1024, 1024), color='white')\n",
    "            img.save(test_path)\n",
    "        test_images.append(test_path)\n",
    "        \n",
    "    \n",
    "    return test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For development with mock data:\n",
    "# dalle_paths = download_dalle_images(save_dir=dalle_dir, num_images=100, use_mock=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For production with real DALL-E\n",
    "# dalle_paths = download_dalle_images(save_dir=dalle_dir, num_images=100, use_mock=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dalle_images(save_dir, num_images, use_mock=True):\n",
    "    \"\"\"\n",
    "    Download or generate test images for the dataset\n",
    "    \n",
    "    Args:\n",
    "        save_dir (str): Directory to save images\n",
    "        num_images (int): Number of images to generate/create\n",
    "        use_mock (bool): Whether to use mock images for development\n",
    "        \n",
    "    Returns:\n",
    "        list: Paths to downloaded/generated images\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    downloaded_paths = []\n",
    "    \n",
    "    if use_mock:\n",
    "        # Use mock generation for development\n",
    "        return mock_dalle_generation(num_images)\n",
    "    \n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    images_to_download = num_images\n",
    "    \n",
    "    while images_to_download > 0:\n",
    "        try:\n",
    "            # Use the rate-limited function\n",
    "            img_url = generate_dalle_image(\"stock photo\", os.getenv('OPENAI_API_KEY'))\n",
    "            if img_url is None:\n",
    "                continue\n",
    "                \n",
    "            img_data = requests.get(img_url).content\n",
    "            img_name = os.path.join(save_dir, f\"dalle_{len(downloaded_paths)}.jpg\")\n",
    "            \n",
    "            with open(img_name, 'wb') as f:\n",
    "                f.write(img_data)\n",
    "                \n",
    "            downloaded_paths.append(img_name)\n",
    "            images_to_download -= 1\n",
    "            time.sleep(1)  # Basic rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during image generation/download: {e}\")\n",
    "            break\n",
    "            \n",
    "    return downloaded_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add this code block after your generate_dalle_image function definition\n",
    "# def test_dalle_generation():\n",
    "#     try:\n",
    "#         # Load API key from environment variables\n",
    "#         api_key = os.getenv('OPENAI_API_KEY')\n",
    "#         if not api_key:\n",
    "#             raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "            \n",
    "#         # Test with a simple prompt\n",
    "#         prompt = \"A simple landscape photo\"\n",
    "#         image_url = generate_dalle_image(prompt, api_key)\n",
    "#         print(\"DALL-E test successful! Image URL:\", image_url)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(f\"Testing DALL-E image generation...\\nTest failed with error: {str(e)}\")\n",
    "#         print(\"DALL-E test failed. Please check your API key and connection.\")\n",
    "#         return False\n",
    "\n",
    "# # Test the function\n",
    "# if __name__ == \"__main__\":\n",
    "#     test_dalle_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DALL-E functionality\n",
    "if test_dalle_download():\n",
    "    print(\"DALL-E test completed successfully!\")\n",
    "else:\n",
    "    print(\"DALL-E test failed. Please check your API key and connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dalle_api_error(error):\n",
    "    \"\"\"Handle different types of DALL-E API errors\"\"\"\n",
    "    if isinstance(error, openai.error.AuthenticationError):\n",
    "        print(\"Error: Invalid API key or authentication failed\")\n",
    "        return \"auth_error\"\n",
    "    elif isinstance(error, openai.error.RateLimitError):\n",
    "        print(\"Error: Rate limit exceeded. Please wait before making more requests\")\n",
    "        return \"rate_limit\"\n",
    "    elif isinstance(error, openai.error.InsufficientQuotaError):\n",
    "        print(\"Error: Insufficient quota or payment required\")\n",
    "        return \"quota_error\"\n",
    "    else:\n",
    "        print(f\"Unexpected error occurred: {str(error)}\")\n",
    "        return \"unknown_error\"\n",
    "\n",
    "def generate_dalle_image(prompt, api_key):\n",
    "    \"\"\"Generate image using DALL-E with error handling\"\"\"\n",
    "    try:\n",
    "        openai.api_key = api_key\n",
    "        response = openai.Image.create(\n",
    "            prompt=prompt,\n",
    "            n=1,\n",
    "            size=\"1024x1024\"\n",
    "        )\n",
    "        return response['data'][0]['url']\n",
    "    except Exception as e:\n",
    "        error_type = handle_dalle_api_error(e)\n",
    "        if error_type == \"auth_error\":\n",
    "            raise ValueError(\"Please check your OpenAI API key\")\n",
    "        elif error_type == \"quota_error\":\n",
    "            raise ValueError(\"Please check your OpenAI account billing status\")\n",
    "        elif error_type == \"rate_limit\":\n",
    "            raise ValueError(\"Rate limit exceeded. Please try again later\")\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)  # Ensure models directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "wandb.login(key=\"7e7d55f5967d9b48d5c46f5008eaa5ad71e02d89\")\n",
    "# Initialize wandb run before model training \n",
    "wandb.init(\n",
    "    project=\"real\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"CustomCNN\",\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss_function\": \"binary_crossentropy\"\n",
    "        \"device\": str(device)  # Add this to track which device is used\n",
    "    }\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not initialize wandb: {e}\")\n",
    "    print(\"Training will continue without logging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WandB setup\n",
    "# wandb.init(project=\"stock-photo-detector\", name=\"training_run_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image_path = self.image_paths[idx]\n",
    "            if not os.path.exists(image_path):\n",
    "                raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "                \n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {self.image_paths[idx]}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Datasets Function\n",
    "def create_datasets(transform):\n",
    "    \"\"\"Create training and validation datasets\"\"\"\n",
    "    # Paths to your image directories\n",
    "    real_dir = './data/real_images' \n",
    "    ai_dir = './data/ai_images'\n",
    "    \n",
    "    # Collect image paths and labels\n",
    "    real_images = [(os.path.join(real_dir, img), 0) for img in os.listdir(real_dir) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    ai_images = [(os.path.join(ai_dir, img), 1) for img in os.listdir(ai_dir) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    all_images = real_images + ai_images\n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    # Split into train and validation\n",
    "    split_idx = int(len(all_images) * 0.8)  # 80% train, 20% validation\n",
    "    train_data = all_images[:split_idx]\n",
    "    val_data = all_images[split_idx:]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ImageDataset(\n",
    "        image_paths=[x[0] for x in train_data],\n",
    "        labels=[x[1] for x in train_data],\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        image_paths=[x[0] for x in val_data],\n",
    "        labels=[x[1] for x in val_data],\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create DataLoaders\n",
    "# Create datasets with proper worker configuration\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset, val_dataset = create_datasets(transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Model Definition\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # Network expects 224x224 images due to the transform\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Image Download Functions ---\n",
    "def download_unsplash_photos(client_id, save_dir, num_photos):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    url = \"https://api.unsplash.com/photos/random\"\n",
    "    headers = {\"Authorization\": f\"Client-ID {client_id}\", \"Accept-Version\": \"v1\"}\n",
    "    \n",
    "    downloaded_paths = []\n",
    "    photos_to_download = num_photos\n",
    "\n",
    "    while photos_to_download > 0:\n",
    "        try:\n",
    "            batch_size = min(30, photos_to_download)\n",
    "            params = {\"count\": batch_size, \"query\": \"stock photo\", \"orientation\": \"landscape\"}\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            photos = response.json()\n",
    "            \n",
    "            for photo in tqdm(photos, desc=\"Downloading photos\"):\n",
    "                img_url = photo['urls']['regular']\n",
    "                img_response = requests.get(img_url)\n",
    "                img_response.raise_for_status()\n",
    "                \n",
    "                img_name = os.path.join(save_dir, f\"{photo['id']}.jpg\")\n",
    "                with open(img_name, 'wb') as f:\n",
    "                    f.write(img_response.content)\n",
    "                \n",
    "                downloaded_paths.append(img_name)\n",
    "\n",
    "            photos_to_download -= len(photos)\n",
    "            time.sleep(1)  # Respect API rate limits\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error downloading photo: {e}\")\n",
    "            break\n",
    "    \n",
    "    return downloaded_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_dalle_images(save_dir, num_images):\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     downloaded_paths = []\n",
    "#     images_to_download = num_images\n",
    "    \n",
    "#     client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "#     while images_to_download > 0:\n",
    "#         try:\n",
    "#             response = client.images.generate(\n",
    "#                 model=\"dall-e-2\", prompt=\"stock photo\", n=1, size=\"1024x1024\"\n",
    "#             )\n",
    "#             img_url = response.data[0].url\n",
    "#             img_data = requests.get(img_url).content\n",
    "#             img_name = os.path.join(save_dir, f\"dalle_{len(downloaded_paths)}.jpg\")\n",
    "#             with open(img_name, 'wb') as f:\n",
    "#                 f.write(img_data)\n",
    "#             downloaded_paths.append(img_name)\n",
    "#             images_to_download -= 1\n",
    "#             time.sleep(1)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error during image generation/download: {e}\")\n",
    "#             break\n",
    "#     return downloaded_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Architecture ---\n",
    "class StockPhotoDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StockPhotoDetector, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 2)  # 2 classes: Real vs AI-generated\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Training Functions\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validation function with progress bar\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Create progress bar for validation\n",
    "    val_pbar = tqdm(val_loader, leave=False, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100. * correct / total\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    # Initialize early stopping\n",
    "    patience = 5\n",
    "    early_stopping_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Initialize wandb run with config\n",
    "    wandb.init(\n",
    "        project=\"real\",\n",
    "        config={\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"architecture\": \"CustomCNN\",\n",
    "            \"batch_size\": train_loader.batch_size,\n",
    "            \"epochs\": num_epochs,\n",
    "            \"optimizer\": optimizer.__class__.__name__,\n",
    "            \"loss_function\": criterion.__class__.__name__\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create progress bar for epochs\n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Create progress bar for batches\n",
    "        batch_pbar = tqdm(train_loader, leave=False, desc=f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for inputs, labels in batch_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update batch progress bar\n",
    "            batch_pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_counter = 0\n",
    "            # Save best model and log to wandb\n",
    "            model_path = 'models/best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss\n",
    "            }, model_path)\n",
    "            wandb.save(model_path)\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f'\\nEarly stopping triggered after {epoch + 1} epochs')\n",
    "            break\n",
    "        \n",
    "        # Update epoch progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f'{train_loss:.4f}',\n",
    "            'train_acc': f'{train_acc:.2f}%',\n",
    "            'val_loss': f'{val_loss:.4f}',\n",
    "            'val_acc': f'{val_acc:.2f}%'\n",
    "        })\n",
    "    \n",
    "    # Finish wandb run\n",
    "    # wandb.finish()\n",
    "    return model\n",
    "\n",
    "    \n",
    "# Cell 11: Training Execution\n",
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Clear CUDA cache if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "model = CustomCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "try:\n",
    "    wandb.init(project=\"real-vs-ai-classifier\", config={\n",
    "        \"epochs\": num_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"CustomCNN\",\n",
    "        \"dataset\": \"Unsplash+DALLE\"\n",
    "    })\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    \n",
    "finally:\n",
    "    wandb.finish()\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Optional Cell 12: Load Best Model\n",
    "def load_best_model():\n",
    "    checkpoint = torch.load('best_model.pth')\n",
    "    model = CustomCNN().to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "# Test data loading and model evaluation\n",
    "sample_batch, sample_labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_batch.shape}\")\n",
    "print(f\"Labels shape: {sample_labels.shape}\")\n",
    "\n",
    "# Test model forward pass\n",
    "sample_output = model(sample_batch.to(device))\n",
    "print(f\"Output shape: {sample_output.shape}\")\n",
    "\n",
    "# Check save directory\n",
    "print(f\"Save directory contents: {os.listdir('models')}\")\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['early_stopping_counter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Run the download and train pipeline ---\n",
    "# unsplash_dir = 'unsplash_photos'\n",
    "# dalle_dir = 'dalle_images'\n",
    "# unsplash_paths = download_unsplash_photos(client_id=\"YOUR_UNSPLASH_CLIENT_ID\", save_dir=unsplash_dir, num_photos=100)\n",
    "# dalle_paths = download_dalle_images(save_dir=dalle_dir, num_images=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the download and train pipeline ---\n",
    "unsplash_dir = 'unsplash_photos'\n",
    "dalle_dir = 'dalle_images'\n",
    "\n",
    "# Download real photos from Unsplash\n",
    "unsplash_paths = download_unsplash_photos(client_id=\"YOUR_UNSPLASH_CLIENT_ID\", save_dir=unsplash_dir, num_photos=100)\n",
    "\n",
    "# For development phase: Use mock DALL-E images to avoid API costs\n",
    "dalle_paths = download_dalle_images(save_dir=dalle_dir, num_images=100, use_mock=True)\n",
    "\n",
    "# Later, when ready for production, you can switch to:\n",
    "# dalle_paths = download_dalle_images(save_dir=dalle_dir, num_images=100, use_mock=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine paths and create labels\n",
    "image_paths = unsplash_paths + dalle_paths\n",
    "labels = [0] * len(unsplash_paths) + [1] * len(dalle_paths)  # 0: Unsplash, 1: DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val/test sets\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = ImageDataset(train_paths, train_labels, transform=transform_augment)\n",
    "val_dataset = ImageDataset(val_paths, val_labels, transform=transform_augment)\n",
    "test_dataset = ImageDataset(test_paths, test_labels, transform=transform_augment)\n",
    "\n",
    "# Data loaders\n",
    "num_workers = min(4, os.cpu_count())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train model\n",
    "model = StockPhotoDetector()\n",
    "train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "# Evaluate on test set\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data loading\n",
    "sample_batch, sample_labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_batch.shape}\")\n",
    "print(f\"Labels shape: {sample_labels.shape}\")\n",
    "\n",
    "# Test model forward pass\n",
    "sample_output = model(sample_batch.to(device))\n",
    "print(f\"Output shape: {sample_output.shape}\")\n",
    "\n",
    "# Check save directory\n",
    "print(f\"Save directory contents: {os.listdir('models')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB setup\n",
    "wandb.init(project=\"stock-photo-detector\", name=\"training_run_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
